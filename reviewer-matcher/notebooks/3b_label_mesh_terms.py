# -*- coding: utf-8 -*-
"""3b-label_mesh_terms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-oEF_iXQQsluYZ6Qme96kvoO3YleDQ3y
"""

!pip install -q abbreviations

"""### **IMPORTS**"""

import requests
import os
import shutil
import pandas as pd
import xml.etree.ElementTree as ET

from google.colab import drive
drive.mount('/content/drive')

"""### **SETTINGS**"""

# call folder
CALL_NAME = '2021-Salut Mental'

# base path
BASE_PATH = '/content/drive/MyDrive/currently/AQuAS/2024AQUAS-ReviewerMatcher'

# code path
CODE_PATH = f'{BASE_PATH}/Implementation/Notebooks'

# data path
DATA_PATH = f'{BASE_PATH}/Implementation/Data'

# mesh url
MESH_URL = 'https://nlmpubs.nlm.nih.gov/projects/mesh/MESH_FILES/xmlmesh/desc2024.xml'

# mesh file path
MESH_FILE_PATH = f'{DATA_PATH}/desc2024.xml'

# local output path
local_output_path = '/content/desc2024.xml'

# input/output paths publications
INPUT_FILE_PATH_PUBLICATIONS = f'{DATA_PATH}/{CALL_NAME}/expert_publications_with_mesh.pkl'
OUTPUT_FILE_PATH_PUBLICATIONS = f'{DATA_PATH}/{CALL_NAME}/expert_publications_with_labels.pkl'

# input/output paths projects
INPUT_FILE_PATH_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/projects_with_mesh.pkl'
OUTPUT_FILE_PATH_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/projects_with_labels.pkl'

# input/output paths all projects
INPUT_FILE_PATH_ALL_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/all_projects_with_mesh.pkl'
OUTPUT_FILE_PATH_ALL_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/all_projects_with_labels.pkl'

# save controls
SAVE_PUBLICATIONS = False
SAVE_PROJECTS = False
SAVE_ALL_PROJECTS = False
SAVE_STATISTICS = False

"""### **FUNCTIONS**"""

# function to download the mesh xml file to a local path
def download_mesh_xml_local(url, local_output_path):
    response = requests.get(url)
    if response.status_code == 200:
        with open(local_output_path, 'wb') as file:
            file.write(response.content)
        print(f"Downloaded MeSH XML file to {local_output_path}")
    else:
        print(f"Failed to download MeSH XML file. Status code: {response.status_code}")

# function to parse mesh xml file
def parse_mesh_xml(mesh_file):
    tree = ET.parse(mesh_file)
    root = tree.getroot()
    mesh_terms = {}

    for descriptor in root.findall('.//DescriptorRecord'):
        ui = descriptor.find('DescriptorUI').text
        name = descriptor.find('DescriptorName/String').text.lower()
        tree_numbers = [tn.text[:3] for tn in descriptor.findall('TreeNumberList/TreeNumber')]

        mesh_terms[name] = {
            'ui': ui,
            'tree_numbers': tree_numbers
        }

    return mesh_terms

# function to categorize mesh terms
def categorize_mesh_terms(mesh_terms):
    categorized_terms = {
        'topics': [],
        'methods': []
    }

    for name, data in mesh_terms.items():  # iterate by name
        # retrieve ui
        descriptor_ui = data['ui']

        for tree_number in data['tree_numbers']:
            # check for topics
            if any(tree_number.startswith(prefix) for prefix in topics_prefixes):
                categorized_terms['topics'].append(name)
            # check for methods
            elif any(tree_number.startswith(prefix) for prefix in methods_prefixes):
                categorized_terms['methods'].append(name)

    # remove duplicates and sort the lists
    categorized_terms['topics'] = sorted(set(categorized_terms['topics']))
    categorized_terms['methods'] = sorted(set(categorized_terms['methods']))

    return categorized_terms

# function to label mesh terms based on extracted terms
def label_mesh_terms(extracted_terms, categorized_terms):
    labels = {
        'topics': [],
        'methods': []
    }

    # split the extracted terms by '|'
    for term in extracted_terms.split('|'):
        term = term.lower().strip()
        # check if the term exists in categorized topics or methods
        if term in categorized_terms['topics']:
            labels['topics'].append(term)
        elif term in categorized_terms['methods']:
            labels['methods'].append(term)

    return labels

# function to create dataframes used to print descriptive statistics
def descriptive_statistics(df):
    # count occurrences of each topic and method
    topic_counts = df['MESH_LABELS'].apply(lambda x: x['topics']).explode().value_counts()
    method_counts = df['MESH_LABELS'].apply(lambda x: x['methods']).explode().value_counts()

    # create df for all topics and methods with their counts
    topic_df = pd.DataFrame({'Term': topic_counts.index, 'Count': topic_counts.values})
    method_df = pd.DataFrame({'Term': method_counts.index, 'Count': method_counts.values})

    # return the df for further processing
    return topic_df, method_df

# function to count tree level 2 occurrences
def count_tree_level_2_occurrences(df, mesh_terms):
    tree_level_2_counts = {}

    for mesh_list in df['MESH_EXTRACTED']:
        for mesh_term in mesh_list.split('|'):
            mesh_term = mesh_term.lower().strip()
            if mesh_term in mesh_terms:
                for tree_number in mesh_terms[mesh_term]['tree_numbers']:
                    if tree_number not in tree_level_2_counts:
                        tree_level_2_counts[tree_number] = 0
                    tree_level_2_counts[tree_number] += 1
            else:
                print(f"Warning: MeSH term '{mesh_term}' not found in mesh_terms dictionary")

    # convert to df for further processing
    tree_level_2_df = pd.DataFrame({
        'Tree_Level_2': list(tree_level_2_counts.keys()),
        'Count': list(tree_level_2_counts.values())
    })

    return tree_level_2_df

"""### **PREP**"""

# download the mesh xml file to local path
download_mesh_xml_local(MESH_URL, local_output_path)

# ensure the directory exists
os.makedirs(DATA_PATH, exist_ok=True)

# copy the file to google drive path
shutil.copy(local_output_path, MESH_FILE_PATH)
print(f"Copied MeSH XML file to {MESH_FILE_PATH}")

# define tree number prefixes for topics and methods
topics_prefixes = ['C', 'D', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'V', 'Z']
methods_prefixes = ['E', 'H', 'I', 'L', 'M', 'N', 'O', 'P', 'R']

# parse the downloaded mesh xml file
mesh_terms = parse_mesh_xml(MESH_FILE_PATH)
categorized_terms = categorize_mesh_terms(mesh_terms)

# print categorized terms to verify the output
print("Categorized Topics:", categorized_terms['topics'])
print("Categorized Methods:", categorized_terms['methods'])

"""### **PUBLICATIONS**"""

# load data
expert_publications_with_mesh = pd.read_pickle(INPUT_FILE_PATH_PUBLICATIONS)

# apply the function to label mesh terms
expert_publications_with_mesh['MESH_LABELS'] = expert_publications_with_mesh['MESH_EXTRACTED'].apply(lambda x: label_mesh_terms(x, categorized_terms))

# save the labeled data
if len(expert_publications_with_mesh)>0 and SAVE_PUBLICATIONS:
  expert_publications_with_mesh.to_pickle(OUTPUT_FILE_PATH_PUBLICATIONS)
  print(f'Publications with MeSH labels saved to {OUTPUT_FILE_PATH_PUBLICATIONS}')

# generate statistics for expert publications
topic_df_publications, method_df_publications = descriptive_statistics(expert_publications_with_mesh)

# print unique counts and top 10 for each
print(f"\nTotal Unique Topics: {topic_df_publications['Term'].nunique()}")
print(f"Total Unique Methods: {method_df_publications['Term'].nunique()}")

print("\nTop 10 Topics:")
print(topic_df_publications.head(10))

print("\nTop 10 Methods:")
print(method_df_publications.head(10))

# generate tree level 2 statistics
tree_level_2_publications = count_tree_level_2_occurrences(expert_publications_with_mesh, mesh_terms)

# print unique counts and top 10 occurrences for tree level 2
print(f"\nTotal Unique Tree Level 2 Categories: {tree_level_2_publications['Tree_Level_2'].nunique()}")

print("\nTop 10 Tree Level 2 Categories:")
print(tree_level_2_publications.sort_values(by='Count', ascending=False).head(10))

# save statistics
if SAVE_STATISTICS:
    topic_df_publications.to_pickle(f'{DATA_PATH}/{CALL_NAME}/expert_publications_topic_statistics.pkl')
    method_df_publications.to_pickle(f'{DATA_PATH}/{CALL_NAME}/expert_publications_method_statistics.pkl')
    tree_level_2_publications.to_pickle(f'{DATA_PATH}/{CALL_NAME}/expert_publications_tree_level_2_statistics.pkl')
    print(f"Saved topic, method, and tree level 2 statistics to {DATA_PATH}/{CALL_NAME}.")

"""### **PROJECTS - 2021**"""

# load data
projects_with_mesh = pd.read_pickle(INPUT_FILE_PATH_PROJECTS)

# apply the function to label mesh terms
projects_with_mesh['MESH_LABELS'] = projects_with_mesh['MESH_EXTRACTED'].apply(lambda x: label_mesh_terms(x, categorized_terms))

# save the labeled data
if len(projects_with_mesh)>0 and SAVE_PROJECTS:
  projects_with_mesh.to_pickle(OUTPUT_FILE_PATH_PROJECTS)
  print(f'Projects with MeSH labels saved to {OUTPUT_FILE_PATH_PROJECTS}')

# generate statistics for projects
topic_df_projects, method_df_projects = descriptive_statistics(projects_with_mesh)

# print unique counts and top 10 for each
print(f"\nTotal Unique Topics: {topic_df_projects['Term'].nunique()}")
print(f"Total Unique Methods: {method_df_projects['Term'].nunique()}")

print("\nTop 10 Topics:")
print(topic_df_projects.head(10))

print("\nTop 10 Methods:")
print(method_df_projects.head(10))

# generate tree level 2 statistics
tree_level_2_projects = count_tree_level_2_occurrences(projects_with_mesh, mesh_terms)

# print unique counts and top 10 occurrences for tree level 2
print(f"\nTotal Unique Tree Level 2 Categories: {tree_level_2_projects['Tree_Level_2'].nunique()}")

print("\nTop 10 Tree Level 2 Categories:")
print(tree_level_2_projects.sort_values(by='Count', ascending=False).head(10))

# save statistics
if SAVE_STATISTICS:
    topic_df_projects.to_pickle(f'{DATA_PATH}/{CALL_NAME}/projects_topic_statistics.pkl')
    method_df_projects.to_pickle(f'{DATA_PATH}/{CALL_NAME}/projects_method_statistics.pkl')
    tree_level_2_projects.to_pickle(f'{DATA_PATH}/{CALL_NAME}/projects_tree_level_2_statistics.pkl')
    print(f"Saved topic, method, and tree level 2 statistics to {DATA_PATH}/{CALL_NAME}.")

"""### **PROJECTS - ALL**"""

# load data
all_projects_with_mesh = pd.read_pickle(INPUT_FILE_PATH_ALL_PROJECTS)

# apply the function to label mesh terms
all_projects_with_mesh['MESH_LABELS'] = all_projects_with_mesh['MESH_EXTRACTED'].apply(lambda x: label_mesh_terms(x, categorized_terms))

# save the labeled data
if len(all_projects_with_mesh)>0 and SAVE_ALL_PROJECTS:
  all_projects_with_mesh.to_pickle(OUTPUT_FILE_PATH_ALL_PROJECTS)
  print(f'All projects with MeSH labels saved to {OUTPUT_FILE_PATH_ALL_PROJECTS}')

# generate statistics for projects
topic_df_all_projects, method_df_all_projects = descriptive_statistics(all_projects_with_mesh)

# print unique counts and top 10 for each
print(f"\nTotal Unique Topics: {topic_df_all_projects['Term'].nunique()}")
print(f"Total Unique Methods: {method_df_all_projects['Term'].nunique()}")

print("\nTop 10 Topics:")
print(topic_df_all_projects.head(10))

print("\nTop 10 Methods:")
print(method_df_all_projects.head(10))

# generate tree level 2 statistics
tree_level_2_all_projects = count_tree_level_2_occurrences(all_projects_with_mesh, mesh_terms)

# print unique counts and top 10 occurrences for tree level 2
print(f"\nTotal Unique Tree Level 2 Categories: {tree_level_2_all_projects['Tree_Level_2'].nunique()}")

print("\nTop 10 Tree Level 2 Categories:")
print(tree_level_2_all_projects.sort_values(by='Count', ascending=False).head(10))

# save statistics
if SAVE_STATISTICS:
    topic_df_all_projects.to_pickle(f'{DATA_PATH}/{CALL_NAME}/all_projects_topic_statistics.pkl')
    method_df_all_projects.to_pickle(f'{DATA_PATH}/{CALL_NAME}/all_projects_method_statistics.pkl')
    tree_level_2_all_projects.to_pickle(f'{DATA_PATH}/{CALL_NAME}/all_projects_tree_level_2_statistics.pkl')
    print(f"Saved topic, method, and tree level 2 statistics to {DATA_PATH}/{CALL_NAME}.")