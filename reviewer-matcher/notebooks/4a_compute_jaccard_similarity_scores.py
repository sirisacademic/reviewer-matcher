# -*- coding: utf-8 -*-
"""4a-compute_jaccard_similarity_scores.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j-G686QhjLIHnNnYmZ18vIARsPXulZz1
"""

# TODO: Modify files before saving in the notebook that generates the data and saves the Pickle files so this is not necessary.
!pip install -q abbreviations

import pandas as pd
import abbreviations
import re

from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import jaccard_score

from google.auth import default
from google.colab import auth
from google.colab import drive

from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

### Input/output paths.

# Specific call folder (used to retrieve the configuration, URLs, etc).
CALL_NAME = '2021-Salut Mental'

# Bath path for all the sample data.
BASE_PATH = '/content/drive/MyDrive/1_Current_projects_SIRIS/2024AQUAS-ReviewerMatcher'

# Code path.
CODE_PATH = f'{BASE_PATH}/Implementation/Notebooks'

# Data path.
DATA_PATH = f'{BASE_PATH}/Implementation/Data'

# Input files.
FILE_PATH_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/projects.pkl'
FILE_PATH_EXPERTS = f'{DATA_PATH}/{CALL_NAME}/experts.pkl'

# Output files.
OUTPUT_FILE_EXPERT_PROJECT_JACCARD_SIMILARITY = f'{DATA_PATH}/{CALL_NAME}/scores/expert_project_jaccard_similarity_scores.pkl'

### Settings

SEPARATOR_VALUES = '|'

### Test size if we want to process a subset for testing. Set as 0 to ignore.

TEST_SIZE_PROJECTS = 0
TEST_SIZE_EXPERTS = 0

# Load data.

df_projects = pd.read_pickle(FILE_PATH_PROJECTS).fillna('')
df_experts = pd.read_pickle(FILE_PATH_EXPERTS).fillna('')

if TEST_SIZE_PROJECTS:
  df_projects = df_projects.head(TEST_SIZE_PROJECTS)

if TEST_SIZE_EXPERTS:
  df_experts = df_experts.head(TEST_SIZE_EXPERTS)

### Functions

# Convert a column of strings to lists, removing empty or whitespace-only entries
def convert_to_list(column_value):
#--------------------------------
    if pd.isna(column_value) or column_value == '':
        return []
    return [item.strip() for item in column_value.split(SEPARATOR_VALUES) if item.strip() != '']

### Compute overlap in expert-project research areas and approaches based on Jaccard similarity.

# Extract all unique research areas and approaches
all_research_areas = set()
all_research_approaches = set()

for col in ['RESEARCH_AREAS', 'RESEARCH_APPROACHES']:
    set_terms = all_research_areas if col == 'RESEARCH_AREAS' else all_research_approaches
    set_terms.update(
        term.strip() for terms in pd.concat([df_experts[col], df_projects[col]]).dropna().apply(lambda x: x.split(SEPARATOR_VALUES))
        for term in terms
        if term.strip()
    )

all_research_areas = list(all_research_areas)
all_research_approaches = list(all_research_approaches)

print(all_research_areas[:10])
print(all_research_approaches[:10])

# One-Hot encoding for experts and projects

# Initialize one-hot encoder
mlb_areas = MultiLabelBinarizer(classes=all_research_areas)
mlb_approaches = MultiLabelBinarizer(classes=all_research_approaches)

# Convert and one-hot encode experts and projects' research areas
expert_areas_one_hot = mlb_areas.fit_transform(df_experts['RESEARCH_AREAS'].apply(lambda x: convert_to_list(x)))
project_areas_one_hot = mlb_areas.transform(df_projects['RESEARCH_AREAS'].apply(lambda x: convert_to_list(x)))

# Convert and one-hot encode experts and projects' for research approaches
expert_approaches_one_hot = mlb_approaches.fit_transform(df_experts['RESEARCH_APPROACHES'].apply(lambda x: convert_to_list(x)))
project_approaches_one_hot = mlb_approaches.transform(df_projects['RESEARCH_APPROACHES'].apply(lambda x: convert_to_list(x)))

# Calculate Jaccard similarity

# Initialize list to store similarity results
expert_project_jaccard_similarity_scores = []

# Iterate over all expert-project pairs
total_iterations = len(df_experts) * len(df_projects)

with tqdm(total=total_iterations, desc="Calculating Jaccard similarity scores") as pbar:
    for expert_index, expert_row in df_experts.iterrows():
        for project_index, project_row in df_projects.iterrows():
            pbar.update(1)

            # Calculate Jaccard Similarity for Research Areas
            area_similarity = jaccard_score(
                expert_areas_one_hot[expert_index],
                project_areas_one_hot[project_index],
                average='binary'
            )

            # Calculate Jaccard Similarity for Research Approaches
            approach_similarity = jaccard_score(
                expert_approaches_one_hot[expert_index],
                project_approaches_one_hot[project_index],
                average='binary'
            )

            # Store the similarity scores
            expert_project_jaccard_similarity_scores.append({
                'Expert_ID': expert_row['ID'],
                'Project_ID': project_row['ID'],
                'Research_Areas_Jaccard_Similarity': area_similarity,
                'Research_Approaches_Jaccard_Similarity': approach_similarity,
            })

# Convert to DataFrame
df_jaccard_similarity_scores = pd.DataFrame(expert_project_jaccard_similarity_scores)

df_jaccard_similarity_scores.head()

# Save the similarity scores to a file for further analysis
df_jaccard_similarity_scores.to_pickle(OUTPUT_FILE_EXPERT_PROJECT_JACCARD_SIMILARITY)
print(f'Expert-project Jaccard similarity scores saved to {OUTPUT_FILE_EXPERT_PROJECT_JACCARD_SIMILARITY}')

df_jaccard_similarity_scores.head()