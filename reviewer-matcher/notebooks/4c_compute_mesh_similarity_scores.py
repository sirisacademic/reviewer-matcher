# -*- coding: utf-8 -*-
"""4c-compute_mesh_similarity_scores.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MnezPgYjMyIXV_cmTH9JmSIt5mHHHZdr
"""

!pip install -q transformers sentence-transformers

# TODO: Modify files before saving in the notebook that generates the data and saves the Pickle files so this is not necessary.
!pip install -q abbreviations

import pandas as pd
import numpy as np
import abbreviations

from sentence_transformers import SentenceTransformer, util
from sklearn.cluster import AgglomerativeClustering
from collections import defaultdict
from google.auth import default
from google.colab import auth
from google.colab import drive
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

### Input/output paths.

# Specific call folder (used to retrieve the configuration, URLs, etc).
CALL_NAME = '2021-Salut Mental'

# Bath path for all the sample data.
BASE_PATH = '/content/drive/MyDrive/1_Current_projects_SIRIS/2024AQUAS-ReviewerMatcher'

# Code path.
CODE_PATH = f'{BASE_PATH}/Implementation/Notebooks'

# Data path.
DATA_PATH = f'{BASE_PATH}/Implementation/Data'

# Input files.
INPUT_FILE_PATH_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/projects_with_mesh.pkl'
INPUT_FILE_PATH_PUBLICATIONS = f'{DATA_PATH}/{CALL_NAME}/expert_publications_with_mesh.pkl'

# Output files.
OUTPUT_FILE_PUBLICATIONS_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/scores/publications_projects_mesh_scores.pkl'
OUTPUT_FILE_EXPERTS_PROJECTS = f'{DATA_PATH}/{CALL_NAME}/scores/expert_projects_mesh_scores.pkl'

OUTPUT_FILE_CLUSTERS = f'{DATA_PATH}/{CALL_NAME}/clusters_mesh_terms.tsv'

SAVE_PUBLICATIONS_PROJECTS = False
SAVE_EXPERTS_PROJECTS = False
SAVE_CLUSTERS = False

### Settings

SEPARATOR_VALUES = '|'

# Semantic similarity thresholds.
DISTANCE_THRESHOLD_CLUSTERS = 0.2
SIMILARITY_THRESHOLD_TERMS = 0.6

### Model used for semantic similarity computation.

MODEL_NAME = 'FremyCompany/BioLORD-2023'

### Test size if we want to process a subset for testing. Set as 0 to ignore.

TEST_SIZE_PROJECTS = 0
TEST_SIZE_PUBLICATIONS = 10

"""Similarity scores from extracted MeSH terms for publications and projects."""

# Load data.

"""
df_publications = pd.DataFrame({
    'ID': [1, 1, 2],
    'MESH_EXTRACTED': ['Dyslexia|Child|Cognition', 'Phonetics|Cognition', 'Reading|Learning|Education']
})

df_projects = pd.DataFrame({
    'ID': ['P1', 'P2'],
    'MESH_EXTRACTED': ['Dyslexia|Cognition|Language', 'Reading|Phonetics|Child']
})
"""

df_projects = pd.read_pickle(INPUT_FILE_PATH_PROJECTS).fillna('')
df_publications = pd.read_pickle(INPUT_FILE_PATH_PUBLICATIONS).fillna('')

if TEST_SIZE_PROJECTS:
  df_projects = df_projects.head(TEST_SIZE_PROJECTS)

if TEST_SIZE_PUBLICATIONS:
  df_publications = df_publications.head(TEST_SIZE_PUBLICATIONS)

df_projects.head()

df_publications[['ID', 'PMID', 'TITLE_PUBMED', 'MESH_EXTRACTED']].head()

# Load model.
model = SentenceTransformer(MODEL_NAME)

## !! TODO: Unify functions used in more than one notebook !!

# Function to compute embeddings for a list of MeSH terms.
def get_embeddings(model, mesh_terms):
#-----------------------------
    terms_list = [term.strip() for term in mesh_terms.split(SEPARATOR_VALUES) if term.strip()]
    if not terms_list:
        return [], None
    embeddings = model.encode(terms_list, convert_to_tensor=True)
    return terms_list, embeddings

# Compute semantic similarity between two lists of phrases.
def compute_list_similarity(model, list1, list2):
#-----------------------------------------------
    if not list1 or not list2:
        return 0, 0
    embeddings1 = model.encode(list1, convert_to_tensor=True)
    embeddings2 = model.encode(list2, convert_to_tensor=True)
    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    avg_similarity = np.mean([max(cosine_scores[:, j]) for j in range(len(list2))])
    max_similarity = np.max(cosine_scores) if cosine_scores.size > 0 else 0
    return avg_similarity, max_similarity

# Function to compute specificity weight based on semantic clusters of MeSH terms
def compute_mesh_specificity_weight(mesh_terms_list, mesh_to_cluster, cluster_counts):
#------------------------------------------------------------------------------------
    if not mesh_terms_list:
        return 0
    weights = []
    for term in mesh_terms_list:
        cluster = mesh_to_cluster.get(term)
        if cluster is not None:
            cluster_frequency = cluster_counts[cluster]
            if cluster_frequency > 0:
                # Inverse frequency as the weight for specificity
                weights.append(1.0 / cluster_frequency)
    return np.mean(weights) if weights else 0

# Using Agglomerative Clustering to group methods based on their embeddings
def cluster_methods(method_embeddings, all_methods, distance_threshold=0.3):
#--------------------------------------------------------------------------
    clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold, metric='cosine', linkage='average')
    method_labels = clustering_model.fit_predict(method_embeddings.cpu().numpy())
    # Return a dictionary to store cluster labels and their corresponding methods
    clusters_dict = defaultdict(list)
    for method, label in zip(all_methods, method_labels):
        clusters_dict[label].append(method)
    return method_labels, clusters_dict

# Create clusters and assign methods to clusters
def create_and_assign_clusters(all_methods, distance_threshold=0.3):
#------------------------------------------------------------------
    # Generate embeddings
    method_embeddings = model.encode(all_methods, convert_to_tensor=True)
    # Perform clustering
    method_labels, clusters_dict = cluster_methods(method_embeddings, all_methods, distance_threshold=distance_threshold)
    # Assign methods to clusters
    method_to_cluster = dict(zip(all_methods, method_labels))
    # Compute cluster-based frequency
    cluster_counts = defaultdict(int)
    for cluster_label in method_labels:
        cluster_counts[cluster_label] += 1
    return method_to_cluster, cluster_counts, clusters_dict

# Function to calculate coverage diversity score with semantic similarity
# to consider giving more weight to experts with multiple publications that cover different aspects of the proposal
def calculate_semantic_coverage_score(model, expert_mesh, proposal_mesh, similarity_threshold=0.7):
#-------------------------------------------------------------------------------------------------
    # Get embeddings for expert and proposal MeSH terms
    expert_terms, expert_embeddings = get_embeddings(model, expert_mesh)
    proposal_terms, proposal_embeddings = get_embeddings(model, proposal_mesh)
    if expert_embeddings is None or proposal_embeddings is None:
        return 0  # Return 0 if embeddings are missing
    # Compute pairwise cosine similarities
    cosine_scores = util.pytorch_cos_sim(expert_embeddings, proposal_embeddings).cpu().numpy()
    # Count the number of terms in the proposal that have a semantic match in the expert's publications
    covered_terms_count = 0
    for j in range(cosine_scores.shape[1]):  # Iterate over proposal terms
        if any(cosine_scores[i, j] >= similarity_threshold for i in range(cosine_scores.shape[0])):
            covered_terms_count += 1
    # Calculate coverage score
    coverage_score = covered_terms_count / len(proposal_terms) if len(proposal_terms) > 0 else 0
    return coverage_score

# Function used to debug and adjust the threshold.
def display_similarity_matrix(expert_terms, proposal_terms, cosine_scores):
#-------------------------------------------------------------------------
    # Convert cosine_scores into a pandas DataFrame for better visualization
    similarity_df = pd.DataFrame(cosine_scores, index=expert_terms, columns=proposal_terms)
    # Display the DataFrame in Colab
    from IPython.display import display
    display(similarity_df)

"""
# COMMENTED as we are not using cluster frequency to capture specificity.

def get_tfidf_dict(all_mesh_terms):
#----------------------------------
    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(SEPARATOR_VALUES), preprocessor=lambda x: x)
    tfidf_matrix = vectorizer.fit_transform(all_mesh_terms)
    feature_names = vectorizer.get_feature_names_out()
    tfidf_dict = dict(zip(feature_names, vectorizer.idf_))
    return tfidf_dict

# Function to compute similarity between a publication and a project proposal weighting MeSH terms according to their TF-IDF.
def compute_weighted_similarity(model, pub_mesh, proj_mesh, tfidf_dict):
#----------------------------------------------------------------------
    pub_terms, pub_embeddings = get_embeddings(model, pub_mesh)
    proj_terms, proj_embeddings = get_embeddings(model, proj_mesh)
    if not pub_terms or not proj_terms:
        return 0
    # Compute pairwise cosine similarities
    cosine_scores = util.pytorch_cos_sim(pub_embeddings, proj_embeddings).numpy()
    # Compute weighted similarity using TF-IDF
    total_weight = 0
    weighted_similarity = 0
    for i, pub_term in enumerate(pub_terms):
        for j, proj_term in enumerate(proj_terms):
            tfidf_weight = tfidf_dict.get(pub_term, 1.0) * tfidf_dict.get(proj_term, 1.0)
            weighted_similarity += cosine_scores[i, j] * tfidf_weight
            total_weight += tfidf_weight
    return weighted_similarity / total_weight if total_weight > 0 else 0
"""

# Extract all unique MeSH terms from publications and projects
all_mesh_terms = [
    term.strip() for mesh_terms in pd.concat([df_publications['MESH_EXTRACTED'], df_projects['MESH_EXTRACTED']]).apply(lambda x: x.split(SEPARATOR_VALUES))
    for term in mesh_terms if term.strip() != ''
]

# Create clusters for MeSH terms
# Lower distance ---> more similar terms in cluster.
mesh_to_cluster, cluster_counts, clusters_dict = create_and_assign_clusters(all_mesh_terms, distance_threshold=DISTANCE_THRESHOLD_CLUSTERS)

# DEBUG
for cluster_label, mesh_terms in clusters_dict.items():
    print(f"Cluster {cluster_label} (Number of MeSH terms: {len(mesh_terms)}):")
    #for mesh_term in mesh_terms:
    #    print(f"  - {mesh_term}")
    #print()

# Create clusters for MeSH terms
print('Generating clusters of MeSH terms...')

# Initialize a list to store cluster information
cluster_data = []

# Iterate over clusters to prepare data for DataFrame
for cluster_label, mesh_terms in clusters_dict.items():
    for mesh_term in mesh_terms:
        cluster_data.append({
            'Cluster_Label': cluster_label,
            'MeSH_Term': mesh_term,
            'Number_of_MeSH_Terms_in_Cluster': len(mesh_terms)
        })

# Create a DataFrame from the cluster data
df_clusters = pd.DataFrame(cluster_data)

# Save the DataFrame to a CSV file.

if SAVE_CLUSTERS:
  df_clusters.to_csv(OUTPUT_FILE_CLUSTERS, sep='\t', index=False)
  print(f'Clusters data saved to {OUTPUT_FILE_CLUSTERS}')

# Step 1: Compute Publication-Project Scores
publication_project_scores = []

# Compute iterations to keep track of progress.
total_iterations = len(df_projects) * len(df_publications)

with tqdm(total=total_iterations, desc="Processing publication-progress pairs") as pbar:

  for _, project_row in df_projects.iterrows():
      for _, pub_row in df_publications.iterrows():

          # Update progress bar.
          pbar.update(1)

          # Extract MeSH terms as lists
          pub_mesh_terms = [term.strip() for term in pub_row['MESH_EXTRACTED'].split(SEPARATOR_VALUES) if term.strip()]
          proj_mesh_terms = [term.strip() for term in project_row['MESH_EXTRACTED'].split(SEPARATOR_VALUES) if term.strip()]

          # Compute similarity between publication and project
          avg_similarity, max_similarity = compute_list_similarity(model, pub_mesh_terms, proj_mesh_terms)

          # Compute specificity weight based on MeSH clusters
          specificity_weight = compute_mesh_specificity_weight(pub_mesh_terms, mesh_to_cluster, cluster_counts)

          # Adjust similarity by specificity weight
          avg_similarity_weighted = avg_similarity * specificity_weight
          max_similarity_weighted = max_similarity * specificity_weight

          # Store the publication-project level scores
          publication_project_scores.append({
              'PMID': pub_row['PMID'],
              'Expert_ID': pub_row['ID'],
              'Project_ID': project_row['ID'],
              'Pub_MeSH_Avg_Similarity': avg_similarity if avg_similarity != 0 else None,
              'Pub_MeSH_Max_Similarity': max_similarity if max_similarity != 0 else None,
              'Pub_MeSH_Avg_Similarity_Weighted': avg_similarity_weighted if avg_similarity_weighted != 0 else None,
              'Pub_MeSH_Max_Similarity_Weighted': max_similarity_weighted if max_similarity_weighted != 0 else None
          })

# Convert to DataFrame
df_publication_scores = pd.DataFrame(publication_project_scores)

df_publication_scores.head()

# Save publication-project scores to file.

if SAVE_PUBLICATIONS_PROJECTS:
  df_publication_scores.to_pickle(OUTPUT_FILE_PUBLICATIONS_PROJECTS)
  print(f'Saved publication-project scores to file {OUTPUT_FILE_PUBLICATIONS_PROJECTS}')

# Step 2: Aggregate to Compute Expert-Project Scores
expert_project_scores = []

# Group publications by Expert_ID and Project_ID
grouped = df_publication_scores.groupby(['Expert_ID', 'Project_ID'])

# Get the total number of expert-project pairs for progress tracking
total_groups = len(grouped)

for (expert_id, project_id), group in tqdm(grouped, total=total_groups, desc="Processing expert-project pairs"):
    # Combine all MeSH terms for an expert to calculate the diversity score
    all_expert_mesh_terms = SEPARATOR_VALUES.join(df_publications[df_publications['ID'] == expert_id]['MESH_EXTRACTED'].unique())
    project_mesh_terms = df_projects[df_projects['ID'] == project_id]['MESH_EXTRACTED'].iloc[0]

    # Calculate semantic coverage score
    mesh_semantic_coverage_score = calculate_semantic_coverage_score(model, all_expert_mesh_terms, project_mesh_terms, similarity_threshold=SIMILARITY_THRESHOLD_TERMS)

    # Handle missing values in the group DataFrame before aggregation by creating a copy
    group_filled = group.fillna(0)

    # Filter out rows where the similarity is zero before calculating averages
    filtered_max_similarity_weighted = group_filled.loc[group_filled['Pub_MeSH_Max_Similarity_Weighted'] != 0, 'Pub_MeSH_Max_Similarity_Weighted']
    filtered_avg_similarity_weighted = group_filled.loc[group_filled['Pub_MeSH_Avg_Similarity_Weighted'] != 0, 'Pub_MeSH_Avg_Similarity_Weighted']
    filtered_max_similarity = group_filled.loc[group_filled['Pub_MeSH_Max_Similarity'] != 0, 'Pub_MeSH_Max_Similarity']
    filtered_avg_similarity = group_filled.loc[group_filled['Pub_MeSH_Avg_Similarity'] != 0, 'Pub_MeSH_Avg_Similarity']

    # Store expert-level results
    expert_project_scores.append({
        'Expert_ID': expert_id,
        'Project_ID': project_id,
        'Expert_MeSH_Semantic_Coverage_Score': mesh_semantic_coverage_score,
        'Expert_MeSH_Max_Similarity_Max': group_filled['Pub_MeSH_Max_Similarity'].max(),
        'Expert_MeSH_Max_Similarity_Avg': filtered_max_similarity.mean() if not filtered_max_similarity.empty else 0,
        'Expert_MeSH_Avg_Similarity_Max': group_filled['Pub_MeSH_Avg_Similarity'].max(),
        'Expert_MeSH_Avg_Similarity_Avg': filtered_avg_similarity.mean() if not filtered_avg_similarity.empty else 0,
        'Expert_MeSH_Max_Similarity_Weighted_Max': group_filled['Pub_MeSH_Max_Similarity_Weighted'].max(),
        'Expert_MeSH_Max_Similarity_Weighted_Avg': filtered_max_similarity_weighted.mean() if not filtered_max_similarity_weighted.empty else 0,
        'Expert_MeSH_Avg_Similarity_Weighted_Max': group_filled['Pub_MeSH_Avg_Similarity_Weighted'].max(),
        'Expert_MeSH_Avg_Similarity_Weighted_Avg': filtered_avg_similarity_weighted.mean() if not filtered_avg_similarity_weighted.empty else 0
    })

# Convert to DataFrame
df_expert_scores = pd.DataFrame(expert_project_scores)

# Save publication-project scores to file.

if SAVE_EXPERTS_PROJECTS:
  df_expert_scores.to_pickle(OUTPUT_FILE_EXPERTS_PROJECTS)
  print(f'Saved expert-project scores to file {OUTPUT_FILE_EXPERTS_PROJECTS}')